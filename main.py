import os
import re
import logging
import asyncio
from dotenv import load_dotenv
import re
from pathlib import Path
import json
import hashlib
import numpy as np
from typing import List
import httpx

from aiogram import Bot, Dispatcher, types
from aiogram.filters import Command
from aiogram.types import InlineKeyboardButton, InlineKeyboardMarkup
from aiogram.exceptions import TelegramForbiddenError, TelegramBadRequest, TelegramRetryAfter
from aiogram.enums import ParseMode, ChatType
from aiogram.client.default import DefaultBotProperties

from collections import deque, defaultdict
from typing import Deque, Dict, Tuple

# ==== OpenAI (–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –∫–ª–∏–µ–Ω—Ç) ====
from openai import AsyncOpenAI, RateLimitError, APIError

# === –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è ===
load_dotenv()
logging.basicConfig(level=logging.INFO)

BOT_TOKEN = os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
CHANNEL = "@MineBridgeOfficial"

if not BOT_TOKEN:
    raise SystemExit("Set BOT_TOKEN in .env")
if not OPENAI_API_KEY:
    raise SystemExit("Set OPENAI_API_KEY in .env")

# === –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ===
# –í–∫–ª—é—á–∞–µ–º Markdown –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
bot = Bot(
    token=BOT_TOKEN,
    default=DefaultBotProperties(parse_mode=ParseMode.MARKDOWN)  # <‚Äî Markdown –≤–∫–ª—é—á—ë–Ω
)
dp = Dispatcher()
openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY, base_url="https://openrouter.ai/api/v1")

# –≥–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è username –±–æ—Ç–∞ (–±–µ–∑ @)
bot_username = "minebridge52bot"

# === –ö–æ–Ω—Ç–µ–∫—Å—Ç N —Å–æ–æ–±—â–µ–Ω–∏–π ===
MAX_HISTORY_MESSAGES = 3  # —Ö—Ä–∞–Ω–∏–º –≤—Å–µ–≥–æ N –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π (user/assistant –≤–ø–µ—Ä–µ–º–µ—à–∫—É)
HistoryKey = Tuple[int, int]  # (chat_id, user_id)
HISTORY: Dict[HistoryKey, Deque[Tuple[str, str]]] = defaultdict(lambda: deque(maxlen=MAX_HISTORY_MESSAGES))

# retry params for OpenAI rate limits
MAX_OPENAI_RETRIES = 2
OPENAI_BACKOFF_BASE = 1.5  # seconds, will use exponential backoff capped below

# === RAG: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –∏ –∫—ç—à ===
KB_DIR = Path(__file__).resolve().parent / "kb"          # –ø–æ–ª–æ–∂–∏—Ç–µ —Å—é–¥–∞ .txt/.md —Ñ–∞–π–ª—ã
RAG_INDEX_DIR = Path(__file__).resolve().parent / ".rag_cache"
RAG_ENABLED = True

RAG_CHUNK_SIZE = 900
RAG_CHUNK_OVERLAP = 150
RAG_TOP_K = 6
RAG_EMB_MODEL = "jina-embeddings-v3"
RAG_EMB_BATCH = 64

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∏–Ω–¥–µ–∫—Å–∞
RAG_CHUNKS: List[dict] = []   # [{id, file, text, mtime}]
RAG_VECS: np.ndarray | None = None
RAG_LOADED = False
RAG_LOCK = asyncio.Lock()

async def _extract_retry_after_seconds(err) -> float | None:
    """–ü–æ–ø—ã—Ç–∞—Ç—å—Å—è –∏–∑–≤–ª–µ—á—å –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –∏–∑ –æ—à–∏–±–∫–∏ OpenAI (headers/–∞—Ç—Ä–∏–±—É—Ç—ã/—Ç–µ–∫—Å—Ç)."""
    # 1) retry-after –≤ headers (–µ—Å–ª–∏ –µ—Å—Ç—å)
    try:
        headers = getattr(err, "headers", None) or {}
        if headers:
            ra = headers.get("retry-after") or headers.get("Retry-After")
            if ra:
                try:
                    return float(ra)
                except Exception:
                    pass
    except Exception:
        pass

    # 2) retry_after –∞—Ç—Ä–∏–±—É—Ç
    try:
        ra = getattr(err, "retry_after", None)
        if ra is not None:
            return float(ra)
    except Exception:
        pass

    # 3) –ø–æ–ø—ã—Ç–∫–∞ —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –≤–∏–¥–∞ "Please try again in 7m12s" –∏–ª–∏ "in 20s"
    try:
        msg = str(err)
        m = re.search(r'(\d+)\s*m(?:in)?\s*(\d+)\s*s', msg)
        if m:
            return int(m.group(1)) * 60 + int(m.group(2))
        m2 = re.search(r'in\s*(\d+)\s*s', msg)
        if m2:
            return int(m2.group(1))
        m3 = re.search(r'(\d+)\s*seconds', msg)
        if m3:
            return int(m3.group(1))
    except Exception:
        pass

    return None

def _shorten(s: str, limit: int = 300) -> str:
    s = (s or "").strip()
    return (s[:limit] + "...") if len(s) > limit else s

def make_key(msg: types.Message) -> HistoryKey:
    return (msg.chat.id, msg.from_user.id)

def build_input_with_history(key: HistoryKey, user_text: str, name: str) -> str:
    """–ì–æ—Ç–æ–≤–∏–º –≤—Ö–æ–¥ –¥–ª—è –º–æ–¥–µ–ª–∏: –∫–æ—Ä–æ—Ç–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç + —Ç–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å."""
    lines: list[str] = []
    hist = HISTORY.get(key)
    if hist:
        lines.append("–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π (–¥–æ 5):")
        for role, text in hist:
            who = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å" if role == "user" else "–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç"
            lines.append(f"{who}: {text}")
        lines.append("‚Äî")  # —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å
    lines.append(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å ({name}): {user_text}")
    lines.append("–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç:")
    print(lines)
    return "\n".join(lines)

def remember_user(key: HistoryKey, text: str) -> None:
    HISTORY[key].append(("user", _shorten(text)))

def remember_assistant(key: HistoryKey, text: str) -> None:
    HISTORY[key].append(("assistant", _shorten(text)))


async def on_startup():
    global bot_username
    try:
        me = await bot.get_me()
        bot_username = (me.username or "").lower()
        logging.info(f"Bot username: @{bot_username}")
    except Exception:
        logging.exception("Failed to get bot username on startup")

    # RAG: –ª–µ–Ω–∏–≤–∞—è —Å–±–æ—Ä–∫–∞ –∏–Ω–¥–µ–∫—Å–∞ (–µ—Å–ª–∏ KB –ø—É—Å—Ç–∞ ‚Äî –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—Å—è)
    try:
        if RAG_ENABLED:
            await _ensure_rag_index()
    except Exception:
        logging.exception("RAG: failed to ensure index on startup")


# === –ó–∞–≥—Ä—É–∑–∫–∞ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º—Ç–∞ –∏–∑ .txt ===
PROMPTS_DIR = Path(__file__).resolve().parent / "prompts"
_PROMPT_CACHE: Dict[str, Tuple[float, str]] = {}

def _read_txt_prompt(path: Path) -> str:
    """
    –ß–∏—Ç–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª –ø—Ä–æ–º—Ç–∞ –∫–∞–∫ –µ—Å—Ç—å (UTF-8), –∫—ç—à–∏—Ä—É–µ—Ç –ø–æ mtime.
    –ü–æ–¥—Ä–µ–∑–∞–µ—Ç BOM –∏ –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –ø–æ –∫—Ä–∞—è–º.
    """
    mtime = path.stat().st_mtime  # FileNotFoundError –ø—Ä–æ–±—Ä–æ—Å–∏—Ç—Å—è –≤—ã—à–µ ‚Äî –ø–æ–π–º–∞–µ–º –≤—ã—à–µ
    cache_key = str(path)
    cached = _PROMPT_CACHE.get(cache_key)
    if cached and cached[0] == mtime:
        return cached[1]

    raw = path.read_text(encoding="utf-8")
    # —É–±—Ä–∞—Ç—å BOM, –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø–µ—Ä–µ–≤–æ–¥—ã —Å—Ç—Ä–æ–∫, –æ–±—Ä–µ–∑–∞—Ç—å –∫—Ä–∞—è
    if raw.startswith("\ufeff"):
        raw = raw.lstrip("\ufeff")
    text = raw.replace("\r\n", "\n").replace("\r", "\n").strip()

    _PROMPT_CACHE[cache_key] = (mtime, text)
    return text

def load_system_prompt_for_chat(chat: types.Chat) -> str:
    """
    –î–ª—è –≥—Ä—É–ø–ø/—Å—É–ø–µ—Ä–≥—Ä—É–ø–ø —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º prompts/<chat_id>.txt,
    –∏–Ω–∞—á–µ ‚Äî prompts/default.txt. –ü—Ä–∏ –ª—é–±–æ–π –æ—à–∏–±–∫–µ ‚Äî –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π fallback.
    """
    try:
        if chat.type in (ChatType.GROUP, ChatType.SUPERGROUP):
            group_path = PROMPTS_DIR / f"{chat.id}.txt"
            if group_path.exists():
                return _read_txt_prompt(group_path)
        # fallback: default.txt
        default_path = PROMPTS_DIR / "default.txt"
        return _read_txt_prompt(default_path)
    except FileNotFoundError:
        logging.warning("Prompt .txt file not found; using builtin fallback")
    except Exception as e:
        logging.exception("Failed to load .txt prompt: %s", e)

    # –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –∑–∞–ø–∞—Å–Ω–æ–π –ø—Ä–æ–º—Ç
    return "–ü–∏—à–∏ —á—Ç–æ —è —Å–µ–≥–æ–¥–Ω—è –Ω–µ —Å–º–æ–≥—É –ø–æ–º–æ—á—å, –º–æ–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º—Ç —Å–ª–æ–º–∞–ª—Å—è."


def _hash(s: str) -> str:
    return hashlib.sha1(s.encode("utf-8")).hexdigest()[:10]

def _read_text_file(p: Path) -> str:
    try:
        raw = p.read_text(encoding="utf-8", errors="ignore")
        if raw.startswith("\ufeff"):
            raw = raw.lstrip("\ufeff")
        return raw.replace("\r\n", "\n").replace("\r", "\n")
    except Exception:
        logging.exception("RAG: failed to read %s", p)
        return ""

def _split_chunks(text: str, size: int = RAG_CHUNK_SIZE, ov: int = RAG_CHUNK_OVERLAP) -> list[str]:
    text = text.strip()
    if not text:
        return []
    out, i = [], 0
    while i < len(text):
        out.append(text[i:i+size])
        i += max(1, size - ov)
    return [c for c in out if c.strip()]

async def _embed_batch(texts: list[str]) -> list[list[float]]:
    """
    –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ —á–µ—Ä–µ–∑ Jina API (—Å—Ç–∞–±–∏–ª—å–Ω–æ –∏ –±—ã—Å—Ç—Ä–æ).
    """
    JINA_KEY = os.environ.get("JINA_API_KEY")
    if not JINA_KEY:
        raise RuntimeError("JINA_API_KEY is not set in environment")

    attempt = 0
    while True:
        try:
            async with httpx.AsyncClient(timeout=60) as s:
                r = await s.post(
                    "https://api.jina.ai/v1/embeddings",
                    headers={
                        "Authorization": f"Bearer {JINA_KEY}",
                        "Accept": "application/json",
                    },
                    json={"model": RAG_EMB_MODEL, "input": texts},
                )
                r.raise_for_status()
                payload = r.json()
                return [item["embedding"] for item in payload["data"]]
        except httpx.HTTPStatusError as e:
            attempt += 1
            if attempt > MAX_OPENAI_RETRIES:
                body = (e.response.text or "")[:500]
                logging.exception("RAG: Jina HTTP %s, body: %s", e.response.status_code, body)
                raise
            wait = min(OPENAI_BACKOFF_BASE * (2 ** (attempt - 1)), 60)
            logging.warning("RAG: Jina HTTP %s, retry %d/%d after %.1fs",
                            e.response.status_code, attempt, MAX_OPENAI_RETRIES, wait)
            await asyncio.sleep(wait)
        except Exception:
            logging.exception("RAG: Jina embeddings request failed")
            raise

async def _ensure_rag_index():
    """–õ–µ–Ω–∏–≤–∞—è —Å–±–æ—Ä–∫–∞/–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ RAG. –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –Ω–∞ —Å—Ç–∞—Ä—Ç–µ –∏ –ø–æ /rag_reindex."""
    global RAG_CHUNKS, RAG_VECS, RAG_LOADED
    async with RAG_LOCK:
        RAG_INDEX_DIR.mkdir(parents=True, exist_ok=True)
        meta_path = RAG_INDEX_DIR / "chunks.json"
        vecs_path = RAG_INDEX_DIR / "vecs.npy"

        # –ó–∞–≥—Ä—É–∑–∏–º, –µ—Å–ª–∏ –µ—Å—Ç—å
        if meta_path.exists() and vecs_path.exists() and not RAG_LOADED:
            try:
                RAG_CHUNKS = json.loads(meta_path.read_text(encoding="utf-8"))
                RAG_VECS = np.load(vecs_path)
                RAG_LOADED = True
                logging.info("RAG: loaded cache with %d chunks", len(RAG_CHUNKS))
            except Exception:
                logging.exception("RAG: failed to load cache, rebuilding")

        # –°–æ–±–µ—Ä—ë–º —Å–ø–∏—Å–æ–∫ –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        kb_files: list[Path] = []
        if KB_DIR.exists():
            for p in KB_DIR.rglob("*"):
                if p.is_file() and p.suffix.lower() in {".txt", ".md"}:
                    kb_files.append(p)

        # –ü–æ—Å—Ç—Ä–æ–∏–º –∫–∞—Ä—Ç—É mtime, —á—Ç–æ–±—ã –ø–æ–Ω—è—Ç—å, —á—Ç–æ –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞—Ç—å
        known = {(c["file"], c.get("mtime", 0.0)): True for c in RAG_CHUNKS}
        need_rebuild = False

        # –ï—Å–ª–∏ –∏–Ω–¥–µ–∫—Å –ø—É—Å—Ç –∏–ª–∏ —Ñ–∞–π–ª–æ–≤ —Å—Ç–∞–ª–æ –±–æ–ª—å—à–µ/–∏–∑–º–µ–Ω–∏–ª–∏—Å—å ‚Äî –ø–µ—Ä–µ—Å—Ç—Ä–æ–∏–º
        existing_paths = {c["file"] for c in RAG_CHUNKS}
        kb_paths = {str(p) for p in kb_files}

        if not RAG_LOADED or existing_paths != kb_paths:
            need_rebuild = True
        else:
            # –°—Ä–∞–≤–Ω–∏–º mtime
            for p in kb_files:
                m = p.stat().st_mtime
                if not any(c["file"] == str(p) and abs(c.get("mtime", 0.0) - m) < 1e-6 for c in RAG_CHUNKS):
                    need_rebuild = True
                    break

        if not need_rebuild:
            return  # –∫—ç—à –≤–∞–ª–∏–¥–µ–Ω

        logging.info("RAG: (re)building index...")
        all_chunks: list[dict] = []
        all_texts: list[str] = []

        for p in kb_files:
            txt = _read_text_file(p)
            parts = _split_chunks(txt)
            m = p.stat().st_mtime
            for i, ch in enumerate(parts):
                cid = f"{_hash(str(p))}:{i}"
                all_chunks.append({"id": cid, "file": str(p), "text": ch, "mtime": m})
                all_texts.append(ch)

        # –≠–º–±–µ–¥–¥–∏–º –±–∞—Ç—á–∞–º–∏
        vecs: list[list[float]] = []
        for i in range(0, len(all_texts), RAG_EMB_BATCH):
            batch = all_texts[i:i+RAG_EMB_BATCH]
            vecs.extend(await _embed_batch(batch))

        if vecs:
            V = np.array(vecs, dtype="float32")
            # –Ω–æ—Ä–º–∏—Ä—É–µ–º –¥–ª—è –∫–æ—Å–∏–Ω—É—Å–∞
            norms = np.linalg.norm(V, axis=1, keepdims=True)
            norms[norms == 0.0] = 1.0
            V /= norms
            RAG_CHUNKS = all_chunks
            RAG_VECS = V
            meta_path.write_text(json.dumps(RAG_CHUNKS, ensure_ascii=False, indent=2), encoding="utf-8")
            np.save(vecs_path, RAG_VECS)
            RAG_LOADED = True
            logging.info("RAG: built %d chunks from %d files", len(RAG_CHUNKS), len(kb_files))
        else:
            RAG_CHUNKS, RAG_VECS, RAG_LOADED = [], None, True
            logging.warning("RAG: no chunks produced (empty kb?)")

async def rag_search(query: str, k: int = RAG_TOP_K) -> list[tuple[dict, float]]:
    if not RAG_ENABLED:
        return []
    await _ensure_rag_index()
    if RAG_VECS is None or len(RAG_CHUNKS) == 0:
        return []
    q_emb = (await _embed_batch([query]))[0]
    q = np.array([q_emb], dtype="float32")
    q /= max(np.linalg.norm(q), 1e-12)
    sims = (RAG_VECS @ q.T).reshape(-1)
    top_idx = np.argsort(-sims)[:k]
    return [(RAG_CHUNKS[i], float(sims[i])) for i in top_idx]

async def rag_build_context(user_query: str, k: int = RAG_TOP_K, max_chars: int = 2000) -> str:
    results = await rag_search(user_query, k=k)
    if not results:
        return ""
    lines = ["–ù–∏–∂–µ –≤—ã–¥–µ—Ä–∂–∫–∏ –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π. –ò—Å–ø–æ–ª—å–∑—É–π –∏—Ö —Ç–æ–ª—å–∫–æ –∫–∞–∫ —Å–ø—Ä–∞–≤–∫—É –∏ –Ω–µ –≤–∫–ª—é—á–∞–π —Å–ª—É–∂–µ–±–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã/—Å—Å—ã–ª–∫–∏ –≤ –æ—Ç–≤–µ—Ç."]
    total = 0
    for ch, sc in results:
        snippet = ch["text"].strip()
        if not snippet:
            continue
        if total + len(snippet) > max_chars:
            snippet = snippet[:max(0, max_chars - total)]
        lines.append(snippet)   # <-- –ë–ï–ó [id]
        total += len(snippet)
        if total >= max_chars:
            break
    lines.append("‚Äî –ö–æ–Ω–µ—Ü –≤—ã–¥–µ—Ä–∂–µ–∫ ‚Äî")
    return "\n".join(lines)


# === –ü–æ–¥–ø–∏—Å–∫–∞ ===
async def is_subscribed(user_id: int) -> bool:
    try:
        member = await bot.get_chat_member(chat_id=CHANNEL, user_id=user_id)
        return member.status in ("creator", "administrator", "member", "restricted")
    except (TelegramForbiddenError, TelegramBadRequest):
        return False
    except Exception:
        logging.exception("Error checking subscription")
        return False


@dp.message(Command("start"))
async def cmd_start(message: types.Message):
    if await is_subscribed(message.from_user.id):
        await message.answer("–ú–∞–π–Ω–∫—Ä–∞—Ñ—Ç —Å–µ—Ä–≤–µ—Ä *–≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ñ—Ñ–ª–∞–π–Ω*.")
        return

    kb = InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="–ü–æ–¥–ø–∏—Å–∞—Ç—å—Å—è", url=f"https://t.me/{CHANNEL.lstrip('@')}")],
        [InlineKeyboardButton(text="–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ–¥–ø–∏—Å–∫—É", callback_data="check_subscription")]
    ])
    await message.answer(
        "–î–ª—è –¥–æ—Å—Ç—É–ø–∞ –Ω—É–∂–µ–Ω –∫–∞–Ω–∞–ª @MineBridgeOfficial ‚Äî –ø–æ–¥–ø–∏—à–∏—Ç–µ—Å—å –∏ –Ω–∞–∂–º–∏—Ç–µ ¬´*–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ–¥–ø–∏—Å–∫—É*¬ª.",
        reply_markup=kb
    )

@dp.message(Command("rag_reindex"))
async def cmd_rag_reindex(message: types.Message):
    if not RAG_ENABLED:
        await message.reply("RAG –æ—Ç–∫–ª—é—á—ë–Ω.")
        return
    sent_msg = await message.reply("üîÑ –ü–µ—Ä–µ—Å—Ç—Ä–∞–∏–≤–∞—é –∏–Ω–¥–µ–∫—Å...")
    try:
        # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –ø–µ—Ä–µ—Å—Ç—Ä–æ–π–∫–∞: —á–∏—Å—Ç–∏–º —Ñ–ª–∞–≥ –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –≤—ã–∑—ã–≤–∞–µ–º ensure
        global RAG_LOADED
        RAG_LOADED = False
        await _ensure_rag_index()
        await safe_edit_to(sent_msg, f"‚úÖ –ì–æ—Ç–æ–≤–æ. –ß–∞–Ω–∫–æ–≤: {len(RAG_CHUNKS)}")
    except Exception as e:
        logging.exception("RAG reindex error")
        await safe_edit_to(sent_msg, f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–µ—Ä–µ—Å—Ç—Ä–æ–π–∫–∏: {e}")


@dp.callback_query()
async def callback_any(query: types.CallbackQuery):
    if query.data != "check_subscription":
        await query.answer()
        return
    if await is_subscribed(query.from_user.id):
        await query.message.answer("–ú–∞–π–Ω–∫—Ä–∞—Ñ—Ç —Å–µ—Ä–≤–µ—Ä *–≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ñ—Ñ–ª–∞–π–Ω*.")
        await query.answer()
    else:
        await query.answer("–ü–æ–¥–ø–∏—Å–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –ø–æ–¥–ø–∏—Å–∞–Ω—ã –Ω–∞ –∫–∞–Ω–∞–ª.", show_alert=True)


# === –ù–æ—Ä–º–∞–ª—å–Ω—ã–π (–ù–ï —Å—Ç—Ä–∏–º–æ–≤—ã–π) –≤—ã–∑–æ–≤ –º–æ–¥–µ–ª–∏ —Å —Ä–µ—Ç—Ä–∞—è–º–∏ –Ω–∞ rate-limit ===
async def complete_openai_nostream(user_text: str, name: str, conv_key: HistoryKey, sys_prompt: str, rag_ctx: str | None = None) -> str:
    """
    –û–¥–Ω–æ—Ä–∞–∑–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –±–µ–∑ —Å—Ç—Ä–∏–º–∞ —á–µ—Ä–µ–∑ chat.completions —Å –±—ç–∫–æ—Ñ—Ñ–æ–º –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∏—Å—Ç–æ—Ä–∏–∏.
    """
    prompt = (user_text or "").strip()
    if not prompt:
        return ""
    prompt = _shorten(prompt)

    # –ó–∞–ø–æ–º–Ω–∏—Ç—å —Ä–µ–ø–ª–∏–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    remember_user(conv_key, prompt)

    input_with_ctx = build_input_with_history(conv_key, prompt, name)
    if rag_ctx:
        input_with_ctx = f"{rag_ctx}\n\n{input_with_ctx}"

    attempt = 0
    while True:
        try:
            resp = await openai_client.chat.completions.create(
                model="x-ai/grok-4-fast:free",
                messages=[
                    {"role": "system", "content": sys_prompt},
                    {"role": "user", "content": input_with_ctx},
                ],
                temperature=0.5,
            )
            text = (resp.choices[0].message.content or "").strip()
            if text:
                remember_assistant(conv_key, text)
            return text
        except (RateLimitError, APIError) as e:
            attempt += 1
            if attempt > MAX_OPENAI_RETRIES:
                logging.exception("OpenAI non-stream rate limit: max retries reached")
                raise
            wait = await _extract_retry_after_seconds(e) or min(OPENAI_BACKOFF_BASE * (2 ** (attempt - 1)), 60)
            logging.warning("OpenAI non-stream rate-limit/API error, retry %d/%d after %.1fs: %s",
                            attempt, MAX_OPENAI_RETRIES, wait, e)
            await asyncio.sleep(wait)


# === –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –æ—Ç–ø—Ä–∞–≤–∫–∏/—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è ===
async def safe_edit_to(msg: types.Message, text: str, markdown: bool = True) -> bool:
    """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π edit_text —Å backoff; –ø—Ä–∏ –ø—Ä–æ–±–ª–µ–º–∞—Ö –ø–∞—Ä—Å–∏–Ω–≥–∞ ‚Äî –ø—Ä–æ–±—É–µ–º –±–µ–∑ Markdown."""
    max_attempts = 4
    attempt = 0
    backoff = 1.0
    while True:
        try:
            await msg.edit_text(text, parse_mode=(ParseMode.MARKDOWN if markdown else None))
            return True
        except TelegramRetryAfter as e:
            attempt += 1
            wait = getattr(e, "retry_after", backoff)
            logging.warning("TelegramRetryAfter on edit: waiting %s seconds (attempt %d)", wait, attempt)
            await asyncio.sleep(wait)
            backoff *= 2
            if attempt >= max_attempts:
                logging.error("Max attempts reached for edit; aborting edit.")
                return False
        except TelegramBadRequest as e:
            if markdown and "can't parse entities" in str(e).lower():
                markdown = False
                continue
            logging.exception("Telegram edit error (bad request): %s", e)
            return False
        except TelegramForbiddenError as e:
            logging.exception("Telegram edit forbidden: %s", e)
            return False
        except Exception:
            logging.exception("Unexpected error while editing message")
            return False

async def safe_send_reply(base_message: types.Message, text: str):
    """–û—Ç–ø—Ä–∞–≤–∏—Ç—å reply —Å backoff (–¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–π)."""
    max_attempts = 4
    attempt = 0
    backoff = 1.0
    while True:
        try:
            return await base_message.reply(text, parse_mode=ParseMode.MARKDOWN)
        except TelegramRetryAfter as e:
            attempt += 1
            wait = getattr(e, "retry_after", backoff)
            logging.warning("TelegramRetryAfter on send: waiting %s seconds (attempt %d)", wait, attempt)
            await asyncio.sleep(wait)
            backoff *= 2
            if attempt >= max_attempts:
                logging.error("Max attempts reached for send; aborting send.")
                return None
        except (TelegramForbiddenError, TelegramBadRequest) as e:
            logging.exception("Telegram send error: %s", e)
            return None
        except Exception:
            logging.exception("Unexpected error while sending message")
            return None

async def send_long_text(initial_msg: types.Message, base_message: types.Message, text: str):
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –¥–ª–∏–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç: –ø–µ—Ä–≤—ã–π –∫—É—Å–æ–∫ ‚Äî —á–µ—Ä–µ–∑ edit, –æ—Å—Ç–∞–ª—å–Ω—ã–µ ‚Äî –æ—Ç–¥–µ–ª—å–Ω—ã–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏.
    """
    CHUNK = 4000  # —Å –∑–∞–ø–∞—Å–æ–º –ø–æ–¥ Markdown
    if not text:
        await safe_edit_to(initial_msg, "*–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç ‚Äî –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ*")
        return

    parts = [text[i:i+CHUNK] for i in range(0, len(text), CHUNK)] or ["..."]

    # –ü–µ—Ä–≤—ã–π –∫—É—Å–æ–∫ ‚Äî –∑–∞–º–µ–Ω—è–µ–º "–ø–µ—á–∞—Ç–∞—é..."
    await safe_edit_to(initial_msg, parts[0])

    # –û—Å—Ç–∞–ª—å–Ω—ã–µ ‚Äî –æ—Ç–¥–µ–ª—å–Ω—ã–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏-—Ä–µ–ø–ª–∞—è–º–∏
    for part in parts[1:]:
        await safe_send_reply(base_message, part)


# === –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–æ–±—â–µ–Ω–∏–π: –æ–±—ã—á–Ω—ã–π –æ—Ç–≤–µ—Ç –±–µ–∑ —Å—Ç—Ä–∏–º–∞ ===
def is_mentioned_or_reply(message: types.Message) -> bool:
    if message.reply_to_message and message.reply_to_message.from_user.is_bot:
        return True

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å—É—â–Ω–æ—Å—Ç–∏-mention (–Ω–∞–ø—Ä–∏–º–µ—Ä @BotName)
    if message.entities and message.text:
        for entity in message.entities:
            if entity.type == "mention":
                mention_text = message.text[entity.offset: entity.offset + entity.length]
                if mention_text.lstrip("@").lower() == bot_username:
                    return True

    # –∏—â–µ–º —Å–ª–æ–≤–æ '–±–æ—Ç'
    if message.text:
        if re.search(r"–±–æ—Ç", message.text.lower()):
            return True

    return False


@dp.message()
async def auto_reply(message: types.Message):
    if not message.text:
        return

    user_id = message.from_user.id

    # === –í–ê–ñ–ù–û: —Ç—Ä–µ–±—É–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ —Ç–æ–ª—å–∫–æ –≤ –≥—Ä—É–ø–ø–∞—Ö/—Å—É–ø–µ—Ä–≥—Ä—É–ø–ø–∞—Ö ===
    is_group = message.chat.type in (ChatType.GROUP, ChatType.SUPERGROUP)
    if is_group and not is_mentioned_or_reply(message):
        logging.info("–ü—Ä–æ–ø—É—â–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –±–µ–∑ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –±–æ—Ç–∞ –∏–ª–∏ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –±–æ—Ç–∞ (–≥—Ä—É–ø–ø–∞).")
        return
    # –í –ª–∏—á–∫–µ (private) ‚Äî –≤—Å–µ–≥–¥–∞ –æ—Ç–≤–µ—á–∞–µ–º

    if not await is_subscribed(user_id) and user_id != 1087968824:
        print(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} –Ω–µ –ø–æ–¥–ø–∏—Å–∞–Ω")
        await message.reply("–ü–æ–¥–ø–∏—à–∏—Ç–µ—Å—å –Ω–∞ @MineBridgeOfficial, —á—Ç–æ–±—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –±–æ—Ç–æ–º.")
        return

    try:
        # (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –ø–æ–∫–∞–∑–∞—Ç—å "–ø–µ—á–∞—Ç–∞–µ—Ç..."
        try:
            await bot.send_chat_action(chat_id=message.chat.id, action="typing")
        except Exception:
            pass

        # –°–æ–æ–±—â–µ–Ω–∏–µ-–∑–∞–≥–ª—É—à–∫–∞
        sent_msg = await message.reply("‚è≥ *–ü–µ—á–∞—Ç–∞—é...*")

        # –ó–∞–≥—Ä—É–∑–∫–∞ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º—Ç–∞ –∏–∑ .txt
        sys_prompt = load_system_prompt_for_chat(message.chat)
        sys_prompt += "\n\n–í–ê–ñ–ù–û: –í –æ—Ç–≤–µ—Ç–µ –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–π —Å–ª—É–∂–µ–±–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ (–≤–∏–¥–∞ [xxxxxxxxxx:0] –∏–ª–∏ 0d829391f3:0)."

        # RAG: –ø–æ–¥–≥–æ—Ç–æ–≤–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ kb
        rag_ctx = ""
        try:
            if RAG_ENABLED:
                rag_ctx = await rag_build_context(message.text, k=RAG_TOP_K, max_chars=2000)
        except Exception:
            logging.exception("RAG: failed to build context")

        username = (message.from_user.username or f"{message.from_user.first_name}")
        conv_key = make_key(message)

        # –û–±—ã—á–Ω—ã–π –∑–∞–ø—Ä–æ—Å (–±–µ–∑ —Å—Ç—Ä–∏–º–∞) —Å —Ä–µ—Ç—Ä–∞—è–º–∏ –ø–æ rate-limit
        answer = await complete_openai_nostream(
            message.text,
            username,
            conv_key,
            sys_prompt,
            rag_ctx=rag_ctx,
        )

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç (–≤–æ–∑–º–æ–∂–Ω–æ –¥–ª–∏–Ω–Ω—ã–π)
        await send_long_text(sent_msg, message, answer)

    except Exception as e:
        logging.exception("–û—à–∏–±–∫–∞ –≤ auto_reply")
        try:
            await safe_edit_to(sent_msg, f"*–ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫* ‚ö†Ô∏è\n{str(e)}")
        except Exception:
            pass


# === –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã ===
async def shutdown():
    try:
        # –£ OpenAI –∫–ª–∏–µ–Ω—Ç–∞ —è–≤–Ω–æ–µ –∑–∞–∫—Ä—ã—Ç–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è; –æ—Å—Ç–∞–≤–ª–µ–Ω–æ –Ω–∞ —Å–ª—É—á–∞–π –∏–∑–º–µ–Ω–µ–Ω–∏–π
        if hasattr(openai_client, "close") and asyncio.iscoroutinefunction(openai_client.close):
            await openai_client.close()
    except Exception:
        pass
    try:
        await bot.session.close()
    except Exception:
        pass


# === –ó–∞–ø—É—Å–∫ ===
async def main():
    await on_startup()
    try:
        await dp.start_polling(bot)
    finally:
        await shutdown()


if __name__ == "__main__":
    asyncio.run(main())
