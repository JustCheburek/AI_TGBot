import os
import re
import logging
import asyncio
from dotenv import load_dotenv
import re
from pathlib import Path
import json
import hashlib
import numpy as np
from typing import List
import httpx

from aiogram import Bot, Dispatcher, types
from aiogram.filters import Command
from aiogram.types import InlineKeyboardButton, InlineKeyboardMarkup
from aiogram.exceptions import TelegramForbiddenError, TelegramBadRequest, TelegramRetryAfter
from aiogram.enums import ParseMode, ChatType
from aiogram.client.default import DefaultBotProperties

from collections import deque, defaultdict
from typing import Deque, Dict, Tuple

# ==== OpenAI (–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –∫–ª–∏–µ–Ω—Ç) ====
from openai import AsyncOpenAI, RateLimitError, APIError

# === –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è ===
load_dotenv()
logging.basicConfig(level=logging.INFO)

BOT_TOKEN = os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
CHANNEL = "@MineBridgeOfficial"

if not BOT_TOKEN:
    raise SystemExit("Set BOT_TOKEN in .env")
if not OPENAI_API_KEY:
    raise SystemExit("Set OPENAI_API_KEY in .env")

# === –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ===
# –í–∫–ª—é—á–∞–µ–º Markdown –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
bot = Bot(
    token=BOT_TOKEN,
    default=DefaultBotProperties(parse_mode=ParseMode.MARKDOWN)  # <‚Äî Markdown –≤–∫–ª—é—á—ë–Ω
)
dp = Dispatcher()
openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY, base_url="https://openrouter.ai/api/v1")

# –≥–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è username –±–æ—Ç–∞ (–±–µ–∑ @)
bot_username = "minebridge52bot"

# === –ö–æ–Ω—Ç–µ–∫—Å—Ç N —Å–æ–æ–±—â–µ–Ω–∏–π ===
MAX_HISTORY_MESSAGES = 3  # —Ö—Ä–∞–Ω–∏–º –≤—Å–µ–≥–æ N –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π (user/assistant –≤–ø–µ—Ä–µ–º–µ—à–∫—É)
HistoryKey = Tuple[int, int]  # (chat_id, user_id)
HISTORY: Dict[HistoryKey, Deque[Tuple[str, str]]] = defaultdict(lambda: deque(maxlen=MAX_HISTORY_MESSAGES))

# retry params for OpenAI rate limits
MAX_OPENAI_RETRIES = 2
OPENAI_BACKOFF_BASE = 1.5  # seconds, will use exponential backoff capped below

# === RAG: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –∏ –∫—ç—à ===
KB_DIR = Path(__file__).resolve().parent / "kb"          # –ø–æ–ª–æ–∂–∏—Ç–µ —Å—é–¥–∞ .txt/.md —Ñ–∞–π–ª—ã
RAG_INDEX_DIR = Path(__file__).resolve().parent / ".rag_cache"
RAG_ENABLED = True

RAG_CHUNK_SIZE = 900
RAG_CHUNK_OVERLAP = 150
RAG_TOP_K = 6
RAG_EMB_MODEL = "jina-embeddings-v3"
RAG_EMB_BATCH = 64

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∏–Ω–¥–µ–∫—Å–∞
RAG_CHUNKS: List[dict] = []   # [{id, file, text, mtime}]
RAG_VECS: np.ndarray | None = None
RAG_LOADED = False
RAG_LOCK = asyncio.Lock()

async def _extract_retry_after_seconds(err) -> float | None:
    """–ü–æ–ø—ã—Ç–∞—Ç—å—Å—è –∏–∑–≤–ª–µ—á—å –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –∏–∑ –æ—à–∏–±–∫–∏ OpenAI (headers/–∞—Ç—Ä–∏–±—É—Ç—ã/—Ç–µ–∫—Å—Ç)."""
    # 1) retry-after –≤ headers (–µ—Å–ª–∏ –µ—Å—Ç—å)
    try:
        headers = getattr(err, "headers", None) or {}
        if headers:
            ra = headers.get("retry-after") or headers.get("Retry-After")
            if ra:
                try:
                    return float(ra)
                except Exception:
                    pass
    except Exception:
        pass

    # 2) retry_after –∞—Ç—Ä–∏–±—É—Ç
    try:
        ra = getattr(err, "retry_after", None)
        if ra is not None:
            return float(ra)
    except Exception:
        pass

    # 3) –ø–æ–ø—ã—Ç–∫–∞ —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –≤–∏–¥–∞ "Please try again in 7m12s" –∏–ª–∏ "in 20s"
    try:
        msg = str(err)
        m = re.search(r'(\d+)\s*m(?:in)?\s*(\d+)\s*s', msg)
        if m:
            return int(m.group(1)) * 60 + int(m.group(2))
        m2 = re.search(r'in\s*(\d+)\s*s', msg)
        if m2:
            return int(m2.group(1))
        m3 = re.search(r'(\d+)\s*seconds', msg)
        if m3:
            return int(m3.group(1))
    except Exception:
        pass

    return None

def _shorten(s: str, limit: int = 300) -> str:
    s = (s or "").strip()
    return (s[:limit] + "...") if len(s) > limit else s

def make_key(msg: types.Message) -> HistoryKey:
    return (msg.chat.id, msg.from_user.id)

def build_input_with_history(key: HistoryKey, user_text: str, name: str) -> str:
    """–ì–æ—Ç–æ–≤–∏–º –≤—Ö–æ–¥ –¥–ª—è –º–æ–¥–µ–ª–∏: –∫–æ—Ä–æ—Ç–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç + —Ç–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å."""
    lines: list[str] = []
    hist = HISTORY.get(key)
    if hist:
        lines.append("–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π (–¥–æ 5):")
        for role, text in hist:
            who = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å" if role == "user" else "–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç"
            lines.append(f"{who}: {text}")
        lines.append("‚Äî")  # —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å
    lines.append(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å ({name}): {user_text}")
    lines.append("–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç:")
    print(lines)
    return "\n".join(lines)

def remember_user(key: HistoryKey, text: str) -> None:
    HISTORY[key].append(("user", _shorten(text)))

def remember_assistant(key: HistoryKey, text: str) -> None:
    HISTORY[key].append(("assistant", _shorten(text)))


async def on_startup():
    global bot_username
    try:
        me = await bot.get_me()
        bot_username = (me.username or "").lower()
        logging.info(f"Bot username: @{bot_username}")
    except Exception:
        logging.exception("Failed to get bot username on startup")

    # RAG: –ª–µ–Ω–∏–≤–∞—è —Å–±–æ—Ä–∫–∞ –∏–Ω–¥–µ–∫—Å–∞ (–µ—Å–ª–∏ KB –ø—É—Å—Ç–∞ ‚Äî –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—Å—è)
    try:
        if RAG_ENABLED:
            await _ensure_rag_index()
    except Exception:
        logging.exception("RAG: failed to ensure index on startup")


# === –ó–∞–≥—Ä—É–∑–∫–∞ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º—Ç–∞ –∏–∑ .txt ===
PROMPTS_DIR = Path(__file__).resolve().parent / "prompts"
_PROMPT_CACHE: Dict[str, Tuple[float, str]] = {}

def _read_txt_prompt(path: Path) -> str:
    """
    –ß–∏—Ç–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª –ø—Ä–æ–º—Ç–∞ –∫–∞–∫ –µ—Å—Ç—å (UTF-8), –∫—ç—à–∏—Ä—É–µ—Ç –ø–æ mtime.
    –ü–æ–¥—Ä–µ–∑–∞–µ—Ç BOM –∏ –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –ø–æ –∫—Ä–∞—è–º.
    """
    mtime = path.stat().st_mtime  # FileNotFoundError –ø—Ä–æ–±—Ä–æ—Å–∏—Ç—Å—è –≤—ã—à–µ ‚Äî –ø–æ–π–º–∞–µ–º –≤—ã—à–µ
    cache_key = str(path)
    cached = _PROMPT_CACHE.get(cache_key)
    if cached and cached[0] == mtime:
        return cached[1]

    raw = path.read_text(encoding="utf-8")
    # —É–±—Ä–∞—Ç—å BOM, –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø–µ—Ä–µ–≤–æ–¥—ã —Å—Ç—Ä–æ–∫, –æ–±—Ä–µ–∑–∞—Ç—å –∫—Ä–∞—è
    if raw.startswith("\ufeff"):
        raw = raw.lstrip("\ufeff")
    text = raw.replace("\r\n", "\n").replace("\r", "\n").strip()

    _PROMPT_CACHE[cache_key] = (mtime, text)
    return text

def load_system_prompt_for_chat(chat: types.Chat) -> str:
    """
    –î–ª—è –≥—Ä—É–ø–ø/—Å—É–ø–µ—Ä–≥—Ä—É–ø–ø —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º prompts/<chat_id>.txt,
    –∏–Ω–∞—á–µ ‚Äî prompts/default.txt. –ü—Ä–∏ –ª—é–±–æ–π –æ—à–∏–±–∫–µ ‚Äî –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π fallback.
    """
    try:
        if chat.type in (ChatType.GROUP, ChatType.SUPERGROUP):
            group_path = PROMPTS_DIR / f"{chat.id}.txt"
            if group_path.exists():
                return _read_txt_prompt(group_path)
        # fallback: default.txt
        default_path = PROMPTS_DIR / "default.txt"
        return _read_txt_prompt(default_path)
    except FileNotFoundError:
        logging.warning("Prompt .txt file not found; using builtin fallback")
    except Exception as e:
        logging.exception("Failed to load .txt prompt: %s", e)

    # –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –∑–∞–ø–∞—Å–Ω–æ–π –ø—Ä–æ–º—Ç
    return "–ü–∏—à–∏ —á—Ç–æ —è —Å–µ–≥–æ–¥–Ω—è –Ω–µ —Å–º–æ–≥—É –ø–æ–º–æ—á—å, –º–æ–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º—Ç —Å–ª–æ–º–∞–ª—Å—è."


def _hash(s: str) -> str:
    return hashlib.sha1(s.encode("utf-8")).hexdigest()[:10]

def _read_text_file(p: Path) -> str:
    try:
        raw = p.read_text(encoding="utf-8", errors="ignore")
        if raw.startswith("\ufeff"):
            raw = raw.lstrip("\ufeff")
        return raw.replace("\r\n", "\n").replace("\r", "\n")
    except Exception:
        logging.exception("RAG: failed to read %s", p)
        return ""

def _split_chunks(text: str, size: int = RAG_CHUNK_SIZE, ov: int = RAG_CHUNK_OVERLAP) -> list[str]:
    text = text.strip()
    if not text:
        return []
    out, i = [], 0
    while i < len(text):
        out.append(text[i:i+size])
        i += max(1, size - ov)
    return [c for c in out if c.strip()]

async def _embed_batch(texts: list[str]) -> list[list[float]]:
    """
    –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ —á–µ—Ä–µ–∑ Jina API (—Å—Ç–∞–±–∏–ª—å–Ω–æ –∏ –±—ã—Å—Ç—Ä–æ).
    """
    JINA_KEY = os.environ.get("JINA_API_KEY")
    if not JINA_KEY:
        raise RuntimeError("JINA_API_KEY is not set in environment")

    attempt = 0
    while True:
        try:
            async with httpx.AsyncClient(timeout=60) as s:
                r = await s.post(
                    "https://api.jina.ai/v1/embeddings",
                    headers={
                        "Authorization": f"Bearer {JINA_KEY}",
                        "Accept": "application/json",
                    },
                    json={"model": RAG_EMB_MODEL, "input": texts},
                )
                r.raise_for_status()
                payload = r.json()
                return [item["embedding"] for item in payload["data"]]
        except httpx.HTTPStatusError as e:
            attempt += 1
            if attempt > MAX_OPENAI_RETRIES:
                body = (e.response.text or "")[:500]
                logging.exception("RAG: Jina HTTP %s, body: %s", e.response.status_code, body)
                raise
            wait = min(OPENAI_BACKOFF_BASE * (2 ** (attempt - 1)), 60)
            logging.warning("RAG: Jina HTTP %s, retry %d/%d after %.1fs",
                            e.response.status_code, attempt, MAX_OPENAI_RETRIES, wait)
            await asyncio.sleep(wait)
        except Exception:
            logging.exception("RAG: Jina embeddings request failed")
            raise

async def _ensure_rag_index():
    """–õ–µ–Ω–∏–≤–∞—è —Å–±–æ—Ä–∫–∞/–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ RAG. –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –Ω–∞ —Å—Ç–∞—Ä—Ç–µ –∏ –ø–æ /rag_reindex."""
    global RAG_CHUNKS, RAG_VECS, RAG_LOADED
    async with RAG_LOCK:
        RAG_INDEX_DIR.mkdir(parents=True, exist_ok=True)
        meta_path = RAG_INDEX_DIR / "chunks.json"
        vecs_path = RAG_INDEX_DIR / "vecs.npy"

        # –ó–∞–≥—Ä—É–∑–∏–º, –µ—Å–ª–∏ –µ—Å—Ç—å
        if meta_path.exists() and vecs_path.exists() and not RAG_LOADED:
            try:
                RAG_CHUNKS = json.loads(meta_path.read_text(encoding="utf-8"))
                RAG_VECS = np.load(vecs_path)
                RAG_LOADED = True
                logging.info("RAG: loaded cache with %d chunks", len(RAG_CHUNKS))
            except Exception:
                logging.exception("RAG: failed to load cache, rebuilding")

        # –°–æ–±–µ—Ä—ë–º —Å–ø–∏—Å–æ–∫ –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        kb_files: list[Path] = []
        if KB_DIR.exists():
            for p in KB_DIR.rglob("*"):
                if p.is_file() and p.suffix.lower() in {".txt", ".md"}:
                    kb_files.append(p)

        # –ü–æ—Å—Ç—Ä–æ–∏–º –∫–∞—Ä—Ç—É mtime, —á—Ç–æ–±—ã –ø–æ–Ω—è—Ç—å, —á—Ç–æ –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞—Ç—å
        known = {(c["file"], c.get("mtime", 0.0)): True for c in RAG_CHUNKS}
        need_rebuild = False

        # –ï—Å–ª–∏ –∏–Ω–¥–µ–∫—Å –ø—É—Å—Ç –∏–ª–∏ —Ñ–∞–π–ª–æ–≤ —Å—Ç–∞–ª–æ –±–æ–ª—å—à–µ/–∏–∑–º–µ–Ω–∏–ª–∏—Å—å ‚Äî –ø–µ—Ä–µ—Å—Ç—Ä–æ–∏–º
        existing_paths = {c["file"] for c in RAG_CHUNKS}
        kb_paths = {str(p) for p in kb_files}

        if not RAG_LOADED or existing_paths != kb_paths:
            need_rebuild = True
        else:
            # –°—Ä–∞–≤–Ω–∏–º mtime
            for p in kb_files:
                m = p.stat().st_mtime
                if not any(c["file"] == str(p) and abs(c.get("mtime", 0.0) - m) < 1e-6 for c in RAG_CHUNKS):
                    need_rebuild = True
                    break

        if not need_rebuild:
            return  # –∫—ç—à –≤–∞–ª–∏–¥–µ–Ω

        logging.info("RAG: (re)building index...")
        all_chunks: list[dict] = []
        all_texts: list[str] = []

        for p in kb_files:
            txt = _read_text_file(p)
            parts = _split_chunks(txt)
            m = p.stat().st_mtime
            for i, ch in enumerate(parts):
                cid = f"{_hash(str(p))}:{i}"
                all_chunks.append({"id": cid, "file": str(p), "text": ch, "mtime": m})
                all_texts.append(ch)

        # –≠–º–±–µ–¥–¥–∏–º –±–∞—Ç—á–∞–º–∏
        vecs: list[list[float]] = []
        for i in range(0, len(all_texts), RAG_EMB_BATCH):
            batch = all_texts[i:i+RAG_EMB_BATCH]
            vecs.extend(await _embed_batch(batch))

        if vecs:
            V = np.array(vecs, dtype="float32")
            # –Ω–æ—Ä–º–∏—Ä—É–µ–º –¥–ª—è –∫–æ—Å–∏–Ω—É—Å–∞
            norms = np.linalg.norm(V, axis=1, keepdims=True)
            norms[norms == 0.0] = 1.0
            V /= norms
            RAG_CHUNKS = all_chunks
            RAG_VECS = V
            meta_path.write_text(json.dumps(RAG_CHUNKS, ensure_ascii=False, indent=2), encoding="utf-8")
            np.save(vecs_path, RAG_VECS)
            RAG_LOADED = True
            logging.info("RAG: built %d chunks from %d files", len(RAG_CHUNKS), len(kb_files))
        else:
            RAG_CHUNKS, RAG_VECS, RAG_LOADED = [], None, True
            logging.warning("RAG: no chunks produced (empty kb?)")

async def rag_search(query: str, k: int = RAG_TOP_K) -> list[tuple[dict, float]]:
    if not RAG_ENABLED:
        return []
    await _ensure_rag_index()
    if RAG_VECS is None or len(RAG_CHUNKS) == 0:
        return []
    q_emb = (await _embed_batch([query]))[0]
    q = np.array([q_emb], dtype="float32")
    q /= max(np.linalg.norm(q), 1e-12)
    sims = (RAG_VECS @ q.T).reshape(-1)
    top_idx = np.argsort(-sims)[:k]
    return [(RAG_CHUNKS[i], float(sims[i])) for i in top_idx]

async def rag_build_context(user_query: str, k: int = RAG_TOP_K, max_chars: int = 2000) -> str:
    """–§–æ—Ä–º–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –±–ª–æ–∫ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∏ —Ü–∏—Ç–∞—Ç–∞–º–∏ [id]."""
    results = await rag_search(user_query, k=k)
    if not results:
        return ""
    lines = ["–ù–∏–∂–µ –≤—ã–¥–µ—Ä–∂–∫–∏ –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π (–∏—Å–ø–æ–ª—å–∑—É–π –∏—Ö –∫–∞–∫ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏ —Ü–∏—Ç–∏—Ä—É–π [id]):"]
    total = 0
    for ch, sc in results:
        snippet = ch["text"].strip()
        if not snippet:
            continue
        if total + len(snippet) > max_chars:
            snippet = snippet[:max(0, max_chars - total)]
        lines.append(f"[{ch['id']}] {snippet}")
        total += len(snippet)
        if total >= max_chars:
            break
    lines.append("‚Äî –ö–æ–Ω–µ—Ü –≤—ã–¥–µ—Ä–∂–µ–∫ ‚Äî")
    return "\n".join(lines)


# === –ü–æ–¥–ø–∏—Å–∫–∞ ===
async def is_subscribed(user_id: int) -> bool:
    try:
        member = await bot.get_chat_member(chat_id=CHANNEL, user_id=user_id)
        return member.status in ("creator", "administrator", "member", "restricted")
    except (TelegramForbiddenError, TelegramBadRequest):
        return False
    except Exception:
        logging.exception("Error checking subscription")
        return False


@dp.message(Command("start"))
async def cmd_start(message: types.Message):
    if await is_subscribed(message.from_user.id):
        await message.answer("–ú–∞–π–Ω–∫—Ä–∞—Ñ—Ç —Å–µ—Ä–≤–µ—Ä *–≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ñ—Ñ–ª–∞–π–Ω*.")
        return

    kb = InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="–ü–æ–¥–ø–∏—Å–∞—Ç—å—Å—è", url=f"https://t.me/{CHANNEL.lstrip('@')}")],
        [InlineKeyboardButton(text="–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ–¥–ø–∏—Å–∫—É", callback_data="check_subscription")]
    ])
    await message.answer(
        "–î–ª—è –¥–æ—Å—Ç—É–ø–∞ –Ω—É–∂–µ–Ω –∫–∞–Ω–∞–ª @MineBridgeOfficial ‚Äî –ø–æ–¥–ø–∏—à–∏—Ç–µ—Å—å –∏ –Ω–∞–∂–º–∏—Ç–µ ¬´*–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ–¥–ø–∏—Å–∫—É*¬ª.",
        reply_markup=kb
    )

@dp.message(Command("rag_reindex"))
async def cmd_rag_reindex(message: types.Message):
    if not RAG_ENABLED:
        await message.reply("RAG –æ—Ç–∫–ª—é—á—ë–Ω.")
        return
    await message.reply("üîÑ –ü–µ—Ä–µ—Å—Ç—Ä–∞–∏–≤–∞—é –∏–Ω–¥–µ–∫—Å...")
    try:
        # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –ø–µ—Ä–µ—Å—Ç—Ä–æ–π–∫–∞: —á–∏—Å—Ç–∏–º —Ñ–ª–∞–≥ –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –≤—ã–∑—ã–≤–∞–µ–º ensure
        global RAG_LOADED
        RAG_LOADED = False
        await _ensure_rag_index()
        await message.reply(f"‚úÖ –ì–æ—Ç–æ–≤–æ. –ß–∞–Ω–∫–æ–≤: {len(RAG_CHUNKS)}")
    except Exception as e:
        logging.exception("RAG reindex error")
        await message.reply(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–µ—Ä–µ—Å—Ç—Ä–æ–π–∫–∏: {e}")


@dp.callback_query()
async def callback_any(query: types.CallbackQuery):
    if query.data != "check_subscription":
        await query.answer()
        return
    if await is_subscribed(query.from_user.id):
        await query.message.answer("–ú–∞–π–Ω–∫—Ä–∞—Ñ—Ç —Å–µ—Ä–≤–µ—Ä *–≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ñ—Ñ–ª–∞–π–Ω*.")
        await query.answer()
    else:
        await query.answer("–ü–æ–¥–ø–∏—Å–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –ø–æ–¥–ø–∏—Å–∞–Ω—ã –Ω–∞ –∫–∞–Ω–∞–ª.", show_alert=True)


async def complete_openai_nostream(user_text: str, name: str, conv_key: HistoryKey, sys_prompt: str, rag_ctx: str | None = None) -> str:
    """–û–¥–Ω–æ—Ä–∞–∑–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –±–µ–∑ —Å—Ç—Ä–∏–º–∞ —á–µ—Ä–µ–∑ chat.completions."""
    prompt = (user_text or "").strip()
    if not prompt:
        return ""
    prompt = _shorten(prompt)
    input_with_ctx = build_input_with_history(conv_key, prompt, name)
    # –í–ù–ò–ú–ê–ù–ò–ï: –∑–¥–µ—Å—å –ù–ï –∑–æ–≤—ë–º remember_user ‚Äî –æ–Ω —É–∂–µ –±—ã–ª –≤–Ω—É—Ç—Ä–∏ stream_openai
    if rag_ctx:
        input_with_ctx = f"{rag_ctx}\n\n{input_with_ctx}"

    resp = await openai_client.chat.completions.create(
        model="x-ai/grok-4-fast:free",
        messages=[
            {"role": "system", "content": sys_prompt},
            {"role": "user", "content": input_with_ctx},
        ],
        temperature=0.5,
    )
    text = (resp.choices[0].message.content or "").strip()
    if text:
        remember_assistant(conv_key, text)
    return text


# === GPT-—Å—Ç—Ä–∏–º —Å —Ç—Ä–æ—Ç—Ç–ª–∏–Ω–≥–æ–º ===
async def stream_openai(user_text: str, name: str, conv_key: HistoryKey, sys_prompt: str, rag_ctx: str | None = None):
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä: –æ—Ç–¥–∞—ë—Ç –¥–µ–ª—å—Ç—ã —Ç–µ–∫—Å—Ç–∞ (—Å—Ç—Ä–æ–∫–∏) –ø–æ –º–µ—Ä–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏.
    –ë—Ä–æ—Å–∞–µ—Ç –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ (—Å–≤–µ—Ä—Ö—É –ø–æ–π–º–∞–µ–º –∏ —É–ø–∞–¥—ë–º –Ω–∞ fallback).
    """
    prompt = (user_text or "").strip()
    if not prompt:
        return

    prompt = _shorten(prompt)
    input_with_ctx = build_input_with_history(conv_key, prompt, name)
    remember_user(conv_key, prompt)

    # –í—Å—Ç–∞–≤–ª—è–µ–º RAG-–∫–æ–Ω—Ç–µ–∫—Å—Ç (–µ—Å–ª–∏ –µ—Å—Ç—å) –ø–µ—Ä–µ–¥ –∏—Å—Ç–æ—Ä–∏–µ–π
    if rag_ctx:
        input_with_ctx = f"{rag_ctx}\n\n{input_with_ctx}"

    logging.info(
        "Calling OpenAI (stream) for user '%s' prompt='%s'",
        name, (prompt[:80] + '...') if len(prompt) > 80 else prompt
    )

    # –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π —Å—Ç—Ä–∏–º SDK —Å retry –Ω–∞ rate-limit
    attempt = 0
    while True:
        try:
            async with openai_client.responses.stream(
                model="x-ai/grok-4-fast:free",
                instructions=sys_prompt,
                input=input_with_ctx,
                temperature=0.5,
            ) as stream:
                full_text_parts: list[str] = []
                async for event in stream:
                    if event.type == "response.output_text.delta":
                        delta = event.delta or ""
                        full_text_parts.append(delta)
                        yield delta
                    elif event.type == "response.error":
                        raise RuntimeError(getattr(event, "error", "OpenAI streaming error"))
                # –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç
                try:
                    final_resp = await stream.get_final_response()
                    final_text = "".join(full_text_parts) if full_text_parts else getattr(final_resp, "output_text", "") or ""
                except Exception as _e:
                    # –ù–µ—Ç response.completed ‚Äî –±–µ—Ä—ë–º —Ç–æ, —á—Ç–æ —É—Å–ø–µ–ª–∏ –Ω–∞–∫–æ–ø–∏—Ç—å
                    logging.warning("No response.completed event, using buffered text: %s", _e)
                    final_text = "".join(full_text_parts)

                if final_text.strip():
                    remember_assistant(conv_key, final_text)
            break  # —É—Å–ø–µ—à–Ω—ã–π —Å—Ç—Ä–∏–º ‚Äî –≤—ã—Ö–æ–¥–∏–º –∏–∑ retry-—Ü–∏–∫–ª–∞
        except (RateLimitError, APIError) as e:
            attempt += 1
            if attempt > MAX_OPENAI_RETRIES:
                logging.exception("OpenAI streaming rate limit: max retries reached")
                raise
            wait = await _extract_retry_after_seconds(e) or min(OPENAI_BACKOFF_BASE * (2 ** (attempt - 1)), 60)
            logging.warning("OpenAI streaming rate-limit/API error, retry %d/%d after %.1fs: %s", attempt, MAX_OPENAI_RETRIES, wait, e)
            await asyncio.sleep(wait)


# === –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –±–æ—Ç–∞ –∏–ª–∏ –æ—Ç–≤–µ—Ç–∞ ===
def is_mentioned_or_reply(message: types.Message) -> bool:
    if message.reply_to_message and message.reply_to_message.from_user.is_bot:
        return True

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å—É—â–Ω–æ—Å—Ç–∏-mention (–Ω–∞–ø—Ä–∏–º–µ—Ä @BotName)
    if message.entities and message.text:
        for entity in message.entities:
            if entity.type == "mention":
                mention_text = message.text[entity.offset: entity.offset + entity.length]
                if mention_text.lstrip("@").lower() == bot_username:
                    return True

    # –∏—â–µ–º —Å–ª–æ–≤–æ '–±–æ—Ç'
    if message.text:
        if re.search(r"–±–æ—Ç", message.text.lower()):
            return True

    return False


@dp.message()
async def auto_reply(message: types.Message):
    if not message.text:
        return

    user_id = message.from_user.id

    # === –í–ê–ñ–ù–û: —Ç—Ä–µ–±—É–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ —Ç–æ–ª—å–∫–æ –≤ –≥—Ä—É–ø–ø–∞—Ö/—Å—É–ø–µ—Ä–≥—Ä—É–ø–ø–∞—Ö ===
    is_group = message.chat.type in (ChatType.GROUP, ChatType.SUPERGROUP)
    if is_group and not is_mentioned_or_reply(message):
        logging.info("–ü—Ä–æ–ø—É—â–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –±–µ–∑ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –±–æ—Ç–∞ –∏–ª–∏ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –±–æ—Ç–∞ (–≥—Ä—É–ø–ø–∞).")
        return
    # –í –ª–∏—á–∫–µ (private) ‚Äî –≤—Å–µ–≥–¥–∞ –æ—Ç–≤–µ—á–∞–µ–º

    if not await is_subscribed(user_id):
        print(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} –Ω–µ –ø–æ–¥–ø–∏—Å–∞–Ω")
        await message.reply("–ü–æ–¥–ø–∏—à–∏—Ç–µ—Å—å –Ω–∞ @MineBridgeOfficial, —á—Ç–æ–±—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –±–æ—Ç–æ–º.")
        return

    # --- –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ —Å backoff/—Ç—Ä–æ—Ç—Ç–ª–∏–Ω–≥–æ–º ---
    max_attempts = 4

    async def safe_edit_to(msg: types.Message, text: str, markdown: bool = True) -> bool:
        """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π edit_text —Å backoff; –ø—Ä–∏ –ø—Ä–æ–±–ª–µ–º–∞—Ö –ø–∞—Ä—Å–∏–Ω–≥–∞ ‚Äî –ø—Ä–æ–±—É–µ–º –±–µ–∑ Markdown."""
        attempt = 0
        backoff = 1.0
        while True:
            try:
                await msg.edit_text(text, parse_mode=(ParseMode.MARKDOWN if markdown else None))
                return True
            except TelegramRetryAfter as e:
                attempt += 1
                wait = getattr(e, "retry_after", backoff)
                logging.warning("TelegramRetryAfter on edit: waiting %s seconds (attempt %d)", wait, attempt)
                await asyncio.sleep(wait)
                backoff *= 2
                if attempt >= max_attempts:
                    logging.error("Max attempts reached for edit; aborting edit.")
                    return False
            except TelegramBadRequest as e:
                # –µ—Å–ª–∏ Markdown –ª–æ–º–∞–µ—Ç—Å—è –Ω–∞ —á–∞—Å—Ç–∏—á–Ω—ã—Ö –æ—Ç–≤–µ—Ç–∞—Ö ‚Äî –ø—Ä–æ–±—É–µ–º –±–µ–∑ parse_mode
                if markdown and "can't parse entities" in str(e).lower():
                    markdown = False
                    continue
                logging.exception("Telegram edit error (bad request): %s", e)
                return False
            except TelegramForbiddenError as e:
                logging.exception("Telegram edit forbidden: %s", e)
                return False
            except Exception:
                logging.exception("Unexpected error while editing message")
                return False
            
    async def safe_send_reply(text: str):
        """–û—Ç–ø—Ä–∞–≤–∏—Ç—å reply —Å backoff (–¥–ª—è —á–∞—Å—Ç–µ–π –æ—Ç–≤–µ—Ç–∞ –ø–æ—Å–ª–µ edit)."""
        attempt = 0
        backoff = 1.0
        while True:
            try:
                return await message.reply(text, parse_mode=ParseMode.MARKDOWN)
            except TelegramRetryAfter as e:
                attempt += 1
                wait = getattr(e, "retry_after", backoff)
                logging.warning("TelegramRetryAfter on send: waiting %s seconds (attempt %d)", wait, attempt)
                await asyncio.sleep(wait)
                backoff *= 2
                if attempt >= max_attempts:
                    logging.error("Max attempts reached for send; aborting send.")
                    return None
            except (TelegramForbiddenError, TelegramBadRequest) as e:
                logging.exception("Telegram send error: %s", e)
                return None
            except Exception:
                logging.exception("Unexpected error while sending message")
                return None

    try:
        # (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –ø–æ–∫–∞–∑–∞—Ç—å "–ø–µ—á–∞—Ç–∞–µ—Ç..."
        try:
            await bot.send_chat_action(chat_id=message.chat.id, action="typing")
        except Exception:
            pass

        # –°–æ–æ–±—â–µ–Ω–∏–µ-–∑–∞–≥–ª—É—à–∫–∞
        sent_msg = await message.reply("‚è≥ *–ü–µ—á–∞—Ç–∞—é...*")

        # –ó–∞–≥—Ä—É–∑–∫–∞ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º—Ç–∞ –∏–∑ TSX
        sys_prompt = load_system_prompt_for_chat(message.chat)

        # RAG: –ø–æ–¥–≥–æ—Ç–æ–≤–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ kb
        rag_ctx = ""
        try:
            if RAG_ENABLED:
                rag_ctx = await rag_build_context(message.text, k=RAG_TOP_K, max_chars=2000)
        except Exception:
            logging.exception("RAG: failed to build context")

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç—Ä–æ—Ç—Ç–ª–∏–Ω–≥–∞ –¥–ª—è —Å—Ç—Ä–∏–º–∞
        CHUNK = 4000               # –ª–∏–º–∏—Ç Telegram –¥–ª—è Markdown —Å –∑–∞–ø–∞—Å–æ–º
        SEND_MIN_CHARS = 100       # –º–∏–Ω–∏–º—É–º –Ω–æ–≤—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤, —á—Ç–æ–±—ã –¥–µ–ª–∞—Ç—å edit
        SEND_MIN_SECONDS = 1.2     # –º–∏–Ω–∏–º—É–º —Å–µ–∫—É–Ω–¥ –º–µ–∂–¥—É edit'–∞–º–∏ –æ–¥–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è

        # –ü–æ–ø—Ä–æ–±—É–µ–º —Å—Ç—Ä–∏–º
        try:
            loop = asyncio.get_running_loop()
            monotonic = loop.time

            active_msg = sent_msg        # —Ç–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä—É–µ–º
            current_chunk_text = ""      # —Ç–µ–∫—Å—Ç –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
            last_sent_len = 0            # —Å–∫–æ–ª—å–∫–æ —É–∂–µ "–∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–æ" –≤ active_msg
            last_edit_ts = monotonic()   # –∫–æ–≥–¥–∞ –≤ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä–∞–∑ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–ª–∏

            username = (message.from_user.username or f"{message.from_user.first_name}")

            async for delta in stream_openai(message.text, username, make_key(message), sys_prompt, rag_ctx=rag_ctx):
                if not delta:
                    continue
                current_chunk_text += delta

                # –µ—Å–ª–∏ –ø–µ—Ä–µ–ø–æ–ª–Ω–∏–ª–∏ –ª–∏–º–∏—Ç —Å–æ–æ–±—â–µ–Ω–∏—è ‚Äî —Ñ–∏–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —ç—Ç–æ—Ç —á–∞–Ω–∫ –∏ —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π
                while len(current_chunk_text) > CHUNK:
                    first_part = current_chunk_text[:CHUNK]
                    rest = current_chunk_text[CHUNK:]

                    # —Ñ–∏–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—É—â–∏–π active_msg (Markdown –º–æ–∂–µ—Ç –±—ã—Ç—å –≤–∞–ª–∏–¥–Ω—ã–º —É–∂–µ —Å–µ–π—á–∞—Å)
                    await safe_edit_to(active_msg, first_part, markdown=True)

                    # —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å—Ä–∞–∑—É —Å —Å–æ–¥–µ—Ä–∂–∏–º—ã–º –æ—Å—Ç–∞—Ç–∫–∞ (—á—Ç–æ–±—ã –Ω–µ –¥–µ–ª–∞—Ç—å –ª–∏—à–Ω–∏–π edit)
                    new_msg = await safe_send_reply(rest if rest.strip() else "...")
                    if new_msg is None:
                        # –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ ‚Äî –ø—Ä–æ—Å—Ç–æ –≤—ã—Ö–æ–¥–∏–º –∏–∑ —Å—Ç—Ä–∏–º–∞
                        raise RuntimeError("Failed to send continuation message")

                    active_msg = new_msg
                    current_chunk_text = rest
                    last_sent_len = len(rest)  # —É–∂–µ –æ—Ç–ø—Ä–∞–≤–∏–ª–∏ —Ü–µ–ª–∏–∫–æ–º –∫–∞–∫ –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                    last_edit_ts = monotonic()

                # —Ç—Ä–æ—Ç—Ç–ª–∏–º —á–∞—Å—Ç–æ—Ç—É edit'–æ–≤: –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –ò –ø–æ —Ä–∞–∑–º–µ—Ä—É –¥–µ–ª—å—Ç—ã
                now = monotonic()
                need_edit = (
                    (len(current_chunk_text) - last_sent_len >= SEND_MIN_CHARS) and
                    (now - last_edit_ts >= SEND_MIN_SECONDS)
                )

                if need_edit:
                    # –í–æ –≤—Ä–µ–º—è —Å—Ç—Ä–∏–º–∞ –ª—É—á—à–µ –±–µ–∑ Markdown, —á—Ç–æ–±—ã –Ω–µ –ø–∞–¥–∞—Ç—å –Ω–∞ –Ω–µ–∑–∞–∫—Ä—ã—Ç—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö
                    ok = await safe_edit_to(active_msg, current_chunk_text, markdown=False)
                    if ok:
                        last_sent_len = len(current_chunk_text)
                        last_edit_ts = now

            # —Å—Ç—Ä–∏–º –∑–∞–≤–µ—Ä—à–∏–ª—Å—è ‚Äî —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –∞–∫–∫—É—Ä–∞—Ç–Ω—ã–π –∞–ø–¥–µ–π—Ç —Å Markdown
            if current_chunk_text:
                await safe_edit_to(active_msg, current_chunk_text, markdown=True)
            else:
                fallback = await complete_openai_nostream(
                    message.text,
                    (message.from_user.username or f"{message.from_user.first_name}"),
                    make_key(message),
                    sys_prompt,
                    rag_ctx=rag_ctx,
                )
                if fallback:
                    await safe_edit_to(active_msg, fallback, markdown=True)
                else:
                    await safe_edit_to(active_msg, "*–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç ‚Äî –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ*", markdown=True)
                    return

        except Exception as e:
            logging.exception("Streaming failed")
            await safe_edit_to(active_msg, f"*–ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫* ‚ö†Ô∏è\n{str(e)}", markdown=True)
            return

    except Exception as e:
        logging.exception("–û—à–∏–±–∫–∞ –≤ auto_reply")
        try:
            await safe_edit_to(active_msg, f"*–ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫* ‚ö†Ô∏è\n{str(e)}", markdown=True)
        except Exception:
            pass


# === –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã ===
async def shutdown():
    try:
        # –£ OpenAI –∫–ª–∏–µ–Ω—Ç–∞ —è–≤–Ω–æ–µ –∑–∞–∫—Ä—ã—Ç–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è; –æ—Å—Ç–∞–≤–ª–µ–Ω–æ –Ω–∞ —Å–ª—É—á–∞–π –∏–∑–º–µ–Ω–µ–Ω–∏–π
        if hasattr(openai_client, "close") and asyncio.iscoroutinefunction(openai_client.close):
            await openai_client.close()
    except Exception:
        pass
    try:
        await bot.session.close()
    except Exception:
        pass


# === –ó–∞–ø—É—Å–∫ ===
async def main():
    await on_startup()
    try:
        await dp.start_polling(bot)
    finally:
        await shutdown()


if __name__ == "__main__":
    asyncio.run(main())
